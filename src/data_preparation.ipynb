{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def start(year):\n",
    "    data_dir = f'/Users/bijubiju/Desktop/databases/australia_property_data/nsw/{year}'\n",
    "    zip_dat_files = os.listdir(data_dir)\n",
    "\n",
    "    #zip_dat_files = [f for f in zip_dat_files if f.endswith('.zip')]\n",
    "    zip_dat_files = [f for f in zip_dat_files if  os.path.isdir(os.path.join(data_dir,f))]\n",
    "    from zipfile import ZipFile\n",
    "    all_dfs = []\n",
    "#print(zip_dat_files)\n",
    "    #print(zip_dat_files)\n",
    "    for zip_file in zip_dat_files:\n",
    "        zip_path = os.path.join(data_dir, zip_file)\n",
    "        \n",
    "        #with ZipFile(zip_path, 'r') as zip_ref:\n",
    "        \n",
    "            # Get list of .dat files in the ZIP\n",
    "        \n",
    "        #dat_files = [f for f in zip_path.namelist() if f.endswith('.DAT')]\n",
    "        #dat_files = [os.path.join(zip_path,f) for f in os.listdir(zip_path) if f.endswith('.DAT')]\n",
    "        #print(dat_files)\n",
    "            # Process each .dat file\n",
    "        #print(zip_path)\n",
    "        #for dat_file in zip_path:\n",
    "                \n",
    "                # Read directly from the ZIP file without extracting\n",
    "                #zip_path = \"/Users/bijubiju/Desktop/databases/australia_property_data/nsw/2023/20230102.zip\"\n",
    "                #dat_filename = \"004_SALES_DATA_NNME_02012023.DAT\"\n",
    "\n",
    "        df =parse_title_references(dat_filename=dat_file)\n",
    "        all_dfs.append(df)\n",
    "    \n",
    "    full_df = pd.concat(all_dfs,ignore_index=True)\n",
    "    full_df.to_csv(f'{year}_property_data.csv')\n",
    "#print(zip_dat_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "def parse_title_references(dat_filename):\n",
    "    \"\"\"\n",
    "    Parse title references from a DAT file\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the DAT file\n",
    "    \"\"\"\n",
    "    # Read the file\n",
    "    #with zipfile.ZipFile(zip_path, 'r') as zip_file:\n",
    "       # with zip_file.open(dat_filename) as file:\n",
    "            # Read and decode the file\n",
    "           # data = file.read().decode('utf-8')\n",
    "    # Split the data into lines and filter for C records\n",
    "    with open(dat_filename,'r',encoding='utf-8') as file:\n",
    "        data = file.read()\n",
    "    lines = [line.strip() for line in data.split('\\n') if line.strip().startswith('B')]\n",
    "    \n",
    "    # Parse each C record\n",
    "    records = []\n",
    "    for line in lines:\n",
    "        fields = line.split(';')\n",
    "        record = {\n",
    "            'district_code': fields[1],\n",
    "            'source': fields[2],\n",
    "            'valuation_num': fields[3],\n",
    "            'property_id': fields[4],\n",
    "            'unit_number': fields[5],\n",
    "            'house_number': fields[6],\n",
    "            'street_name': fields[7],\n",
    "            'suburb_name': fields[8],\n",
    "            'postcode': fields[9],\n",
    "            'contract_date': fields[10],\n",
    "            'purchase_price': fields[11],\n",
    "            'land_description': fields[12],\n",
    "            'area': fields[13],\n",
    "            'area_type': fields[14],\n",
    "            'dimensions': fields[15],\n",
    "            'comp_code': fields[16],\n",
    "            'zone_code': fields[17],\n",
    "            'vendor_name': fields[18],\n",
    "            'purchaser_name': fields[19],\n",
    "            \n",
    "        }\n",
    "        records.append(record)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(records)\n",
    "    \n",
    "    # Convert dates and numeric fields\n",
    "   \n",
    "    df['contract_date'] = pd.to_datetime(df['contract_date'], format='%Y%m%d', errors='coerce')\n",
    "    \n",
    "    df['purchase_price'] = pd.to_numeric(df['purchase_price'], errors='coerce')\n",
    "    df['area'] = pd.to_numeric(df['area'], errors='coerce')\n",
    "    return df\n",
    "# Example usage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_title_references_pre_2002(dat_filename):\n",
    "    \"\"\"\n",
    "    Parse title references from a DAT file\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the DAT file\n",
    "    \"\"\"\n",
    "    # Read the file\n",
    "    #with zipfile.ZipFile(zip_path, 'r') as zip_file:\n",
    "       # with zip_file.open(dat_filename) as file:\n",
    "            # Read and decode the file\n",
    "           # data = file.read().decode('utf-8')\n",
    "    # Split the data into lines and filter for C records\n",
    "    print(dat_filename)\n",
    "    with open(dat_filename,'r',encoding='utf-8') as file:\n",
    "        data = file.read()\n",
    "    lines = [line.strip() for line in data.split('\\n') if line.strip().startswith('B')]\n",
    "    print(len(lines))\n",
    "    # Parse each C record\n",
    "    records = []\n",
    "    for line in lines:\n",
    "        fields = line.split(';')\n",
    "        record = {\n",
    "            'district_code': fields[1],\n",
    "            'source': fields[2],\n",
    "            'valuation_num': fields[3],\n",
    "            'property_id': fields[4],\n",
    "            'unit_number': fields[5],\n",
    "            'house_number': fields[6],\n",
    "            'street_name': fields[7],\n",
    "            'suburb_name': fields[8],\n",
    "            'postcode': fields[9],\n",
    "            'contract_date': fields[10],\n",
    "            'purchase_price': fields[11],\n",
    "            'land_description': fields[12],\n",
    "            'area': fields[13],\n",
    "            'area_type': fields[14],\n",
    "            'dimensions': fields[15],\n",
    "            'comp_code': fields[16],\n",
    "            'zone_code': fields[17],\n",
    "            'vendor_name': fields[18],\n",
    "            'purchaser_name': fields[19],\n",
    "            \n",
    "        }\n",
    "        records.append(record)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(records)\n",
    "    \n",
    "    # Convert dates and numeric fields\n",
    "   \n",
    "    df['contract_date'] = pd.to_datetime(df['contract_date'], format='%Y%m%d', errors='coerce')\n",
    "    \n",
    "    df['purchase_price'] = pd.to_numeric(df['purchase_price'], errors='coerce')\n",
    "    df['area'] = pd.to_numeric(df['area'], errors='coerce')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "all_dfs = []\n",
    "#print(zip_dat_files)\n",
    "for zip_file in zip_dat_files:\n",
    "        zip_path = os.path.join(data_dir, zip_file)\n",
    "        \n",
    "        #with ZipFile(zip_path, 'r') as zip_ref:\n",
    "        \n",
    "            # Get list of .dat files in the ZIP\n",
    "        \n",
    "        #dat_files = [f for f in zip_path.namelist() if f.endswith('.DAT')]\n",
    "        dat_files = [os.path.join(zip_path,f) for f in os.listdir(zip_path) if f.endswith('.DAT')]\n",
    "        #print(dat_files)\n",
    "            # Process each .dat file\n",
    "        for dat_file in dat_files:\n",
    "                \n",
    "                # Read directly from the ZIP file without extracting\n",
    "                #zip_path = \"/Users/bijubiju/Desktop/databases/australia_property_data/nsw/2023/20230102.zip\"\n",
    "                #dat_filename = \"004_SALES_DATA_NNME_02012023.DAT\"\n",
    "\n",
    "                df =parse_title_references(dat_filename=dat_file)\n",
    "                all_dfs.append(df)\n",
    "    \n",
    "full_df = pd.concat(all_dfs,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/bijubiju/Desktop/databases/australia_property_data/nsw/2013/April 01, 2013 (NNME)/250_SALES_DATA_NNME_01042013.DAT\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "#for year in range(1990,2000):\n",
    "   #print(year)\n",
    "   #start(year)\n",
    "start(2001)\n",
    "#start(2012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/bijubiju/Desktop/databases/australia_property_data/nsw/2001/Archive Sales 2001/ARCHIVE_SALES_2001.DAT\n",
      "21643\n"
     ]
    }
   ],
   "source": [
    "year = 1990\n",
    "dat_filename = \"/Users/bijubiju/Desktop/databases/australia_property_data/nsw/2001/Archive Sales 2001/ARCHIVE_SALES_2001.DAT\"\n",
    "df = parse_title_references_pre_2002(dat_filename)\n",
    "df.to_csv(\"2001_property_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
